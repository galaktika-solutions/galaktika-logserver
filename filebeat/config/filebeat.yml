filebeat:
  spool_size: 1024
  idle_timeout: "5s"
  # List of prospectors to fetch data.
  prospectors:
    # Each - is a prospector. Below are the prospector specific configurations
    -
      # Paths that should be crawled and fetched. Glob based paths.
      # For each file found under this path, a harvester is started.
      input_type: log
      paths:
        - "/var/lib/docker/containers/*/*.log"
      document_type: Docker
      ignore_older: 1h
      close_older: 2h
      harvester_buffer_size: 16384
      scan_frequency: "10s"
      fields:
        server: "egyed"
      json.keys_under_root: true
      json.add_error_key: true
      json.message_key: log
    -
      paths:
        - "/var/log/auth.log"
      document_type: sudo
      ignore_older: 1h
      close_older: 2h
      harvester_buffer_size: 16384
      scan_frequency: "10s"
      fields:
        server: "egyed"
      json.keys_under_root: true
      json.add_error_key: true
      json.message_key: log
      # - c:\programdata\elasticsearch\logs\*

      # Type of the files. Based on this the way the file is read is decided.
      # The different types cannot be mixed in one prospector
      #
      # Possible options are:
      # * log: Reads every line of the log file (default)
      # * stdin: Reads the standard in
  registry_file: /var/lib/filebeat/registry

output:
  logstash:
    hosts: ["logstash:5000"]
